{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4659c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b85c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059e7bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dogcat\\\\cat.csv\")\n",
    "df2 = df.copy()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a105b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    id_value = row[\"id\"]\n",
    "    label_value = row[\"label\"]\n",
    "    id_value -= 1\n",
    "    id_str = str(id_value)\n",
    "    value = f\"cat.{id_str}.JPG\"\n",
    "    #print(value)\n",
    "    #print(label_value)\n",
    "    df[\"id\"] = value\n",
    "    df[\"label\"] = label_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b319395",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df2.iterrows():\n",
    "    id_value = row[\"id\"]\n",
    "    label_value = row[\"label\"]\n",
    "    id_value -= 1\n",
    "    id_str = str(id_value)\n",
    "    value = f\"dog.{id_str}.JPG\"\n",
    "    #print(value)\n",
    "    #print(label_value)\n",
    "    df2[\"id\"] = value\n",
    "    df2[\"label\"] = label_value+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d49f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  id  label\n",
      "0      cat.12499.JPG      0\n",
      "1      cat.12499.JPG      0\n",
      "2      cat.12499.JPG      0\n",
      "3      cat.12499.JPG      0\n",
      "4      cat.12499.JPG      0\n",
      "...              ...    ...\n",
      "12495  dog.12499.JPG      1\n",
      "12496  dog.12499.JPG      1\n",
      "12497  dog.12499.JPG      1\n",
      "12498  dog.12499.JPG      1\n",
      "12499  dog.12499.JPG      1\n",
      "\n",
      "[25000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.concat([df, df2], axis=0)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59aa85ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class catdogDataset(Dataset):\n",
    "    def __init__(self, annotation, rootdic, transform = None, target_size=(224, 224)):\n",
    "        self.annotation = annotation\n",
    "        self.rootdic = rootdic\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotation)\n",
    "    def __getitem__(self, index):\n",
    "        imgPath = os.path.join(self.rootdic, self.annotation.iloc[index, 0])\n",
    "        image = io.imread(imgPath)\n",
    "        image = resize(image, self.target_size, anti_aliasing=True) # convert the image into 224x224\n",
    "        \n",
    "        y = torch.tensor([float(self.annotation.iloc[index, 1])])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return (image, y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0976f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = catdogDataset(annotation = result_df, rootdic = \"dogcat\\\\traindata\", transform = transforms.ToTensor(), target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e190a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = torch.utils.data.random_split(dataset, [20000, 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea939dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channel = 3\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad23dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_set, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_set, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57d4025f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "for batch, (data, target) in enumerate(test_loader):\n",
    "    print(data.shape)\n",
    "    print(target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8de28f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6993a4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "for param in vgg16.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Enable gradients for the final fully connected layer\n",
    "vgg16.classifier[6].requires_grad = True\n",
    "\n",
    "# Print the model summary to inspect the architecture\n",
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fa988a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = vgg16.classifier[6].in_features\n",
    "vgg16.classifier[6] = nn.Linear(num_features, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ce999e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(vgg16.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b396b2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f18f350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0035\n",
      "Epoch [2/5], Loss: 0.0014\n",
      "Epoch [3/5], Loss: 0.0006\n",
      "Epoch [4/5], Loss: 0.0003\n",
      "Epoch [5/5], Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Modify the optimizer to only optimize parameters with gradients\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, vgg16.parameters()), lr=0.0001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    vgg16.train()\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(torch.float32)\n",
    "        labels = labels.to(torch.float32) \n",
    "\n",
    "        outputs = vgg16(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Learning rate scheduling step\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation (optional) - evaluate on your validation set here if available\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdb0b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and additional information\n",
    "checkpoint = {\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': vgg16.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss.item(),\n",
    "    # Add any other information you want to save\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'saved_vgg16.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c946b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)\n",
    "num_features = vgg16.classifier[6].in_features\n",
    "vgg16.classifier[6] = nn.Linear(num_features, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a93b32b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the model\n",
    "#model = VGG_net(in_channels=3, num_classes=1)\n",
    "\n",
    "# Load the saved model\n",
    "checkpoint = torch.load('saved_vgg16.pth')\n",
    "\n",
    "# Load the model's state dictionary\n",
    "vgg16.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Load the optimizer's state dictionary (if needed)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Other information, e.g., epoch, loss\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "# Set the model to evaluation mode (for inference)\n",
    "vgg16.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "641740ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def inference_single_image(model, image_path):\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image = image.to(device)\n",
    "        output = model(image)\n",
    "        print(output)\n",
    "        probability = torch.sigmoid(output).item()\n",
    "    \n",
    "    return probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3dedb583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1555]])\n",
      "0.4612075388431549\n"
     ]
    }
   ],
   "source": [
    "image_path = \"C:\\\\Users\\\\Admin\\\\dogcat\\\\54.jpg\"\n",
    "probability = inference_single_image(vgg16, image_path)\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c45ead9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(probability, threshold=0.5):\n",
    "    if probability > threshold:\n",
    "        return \"Dog\"\n",
    "    else:\n",
    "        return \"Cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08b2a930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: Cat\n"
     ]
    }
   ],
   "source": [
    "class_prediction = predict_class(probability)\n",
    "print(f\"The predicted class is: {class_prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8868b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
